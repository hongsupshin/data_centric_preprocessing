# Abstract

Hardware verification is a compute-intensive process due to design complexity. ML can make this process more efficient by identifying tests with high probability of producing desired outcome. However, the verification data pose a unique challenge in developing a robust ML system. First, the data have high non-stationarity. In addition to their distributions, the type and size of the features change over time, and schemas are not available. Second, the data are highly heterogeneous and often have multiple interpretations. High dimensionality of data aggravates these issues. I propose a data-centric ML pipeline that infers schema from training data, resolves mismatch during model serving, and allows “data tuning” (tuning data preprocessing methods). This pipeline is adaptive to changes in future data and thus increases deployment scalability and robustness. Real-world benchmark testing also shows that data tuning with this pipeline improves model performance.
