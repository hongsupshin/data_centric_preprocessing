# Abstract

Hardware verification is a compute-intensive process due to design complexity. Using ML can make this process more efficient, but the verification data pose a unique challenge in developing robust ML systems. First, data types and sizes change over time. Second, data are highly heterogeneous and have multiple interpretations. High dimensionality and lack of schema aggravate these issues. I propose an ML pipeline that is adaptive to future changes and allows “data tuning” (tuning preprocessing methods) that increases post-deployment scalability and robustness. The pipeline infers schema from training data and conducts preprocessing accordingly. It monitors type changes and resolves any mismatches during serving. This way, the pipeline increases transparency and efficiency in data preprocessing. Additionally, real-world benchmark testing shows that the data tuning technique can improve model performance.